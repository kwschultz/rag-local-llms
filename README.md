## Langchain RAG with local LLMs

Experimenting with Retrieval Augmented Generation (RAG) using local LLMs.
<br>
- Tech used: Ollama LLM wrapper, Chroma, Langchain, Mistral LLM model, Nomic Embeddings.
- Runtime: Everything is run locally on Apple M1 CPU. 


Adapted from [pixegami/rag-tutorial-v2])(https://github.com/pixegami/rag-tutorial-v2)
